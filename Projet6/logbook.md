# RÃ©alisation d'une ACP

## Qu'est ce que c'est ? 

L'Analyse en Composantes Principales (ACP) est une mÃ©thode statistique de **rÃ©duction de dimensionnalitÃ©** qui transforme des variables corrÃ©lÃ©es en un ensemble de variables indÃ©pendantes appelÃ©es composantes principales.

Son objectif global est de simplifier les donnÃ©es tout en conservant le maximum d'information, facilitant ainsi leur analyse et leur visualisation. 
  
## Quand faire une ACP ?

Lâ€™ACP est particuliÃ¨rement utile lorsque **le nombre de variables quantitatives dÃ©passe un certain seuil** oÃ¹ leur analyse devient difficile, **gÃ©nÃ©ralement Ã  partir de 5-10 variables**, mais <u>cela dÃ©pend de la corrÃ©lation entre elles et de lâ€™objectif dâ€™analyse</u>.

## Comment fonctionne une ACP ? 

Lâ€™ACP transforme les variables initiales en un nouvel ensemble de variables appelÃ©es **composantes principales**, chacune correspondant Ã  une combinaison linÃ©aire des variables dâ€™origine â€” autrement dit, chaque composante est construite Ã  partir dâ€™un mÃ©lange pondÃ©rÃ© des variables de dÃ©part, avec des coefficients qui reflÃ¨tent leur importance.

Ces composantes sont triÃ©es par ordre de **variance expliquÃ©e** (câ€™est-Ã -dire la quantitÃ© dâ€™information conservÃ©e) : la premiÃ¨re composante (PC1) explique le maximum de variance, suivie par la deuxiÃ¨me (PC2), puis la troisiÃ¨me (PC3), etc.

En pratique, on cherche Ã  conserver un nombre de composantes suffisant pour expliquer une part importante de la variance totale. Il nâ€™existe pas de seuil universel, mais voici quelques repÃ¨res frÃ©quemment utilisÃ©s selon le contexte :

| % de variance expliquÃ©e | Usage courant                                                             |
| ----------------------- | ------------------------------------------------------------------------- |
| **70 %**                | Minimum acceptable pour des visualisations ou une exploration rapide      |
| **80â€“90 %**             | Bon compromis entre simplification et fidÃ©litÃ© aux donnÃ©es                |
| **> 95 %**              | Rarement nÃ©cessaire ; peu utile si lâ€™objectif est de rÃ©duire la dimension |

ğŸ’¡ Une bonne pratique consiste Ã  lancer une ACP sur lâ€™ensemble des donnÃ©es dÃ¨s le dÃ©part, puis Ã  observer le **Scree plot** pour dÃ©terminer Ã  partir de **combien de composantes principales on dÃ©passe le seuil de variance expliquÃ©e que lâ€™on sâ€™est fixÃ©** (par exemple 80 % ou 90 %). Cela permet de choisir objectivement le nombre de dimensions Ã  conserver pour la suite de lâ€™analyse.

Une fois le nombre de composantes principales retenues, lâ€™ACP fournit une matrice de **loadings**, qui contient les **coefficients associÃ©s Ã  chaque variable pour chaque composante**. Ces coefficients indiquent dans **quelle direction chaque variable "pÃ¨se"** dans la crÃ©ation de chaque axe.
> **Autrement dit, chaque composante principale (PC1, PC2, etc.) est une sorte de nouvelle variable construite Ã  partir dâ€™un mÃ©lange pondÃ©rÃ© des variables dâ€™origine.**

Les loadings permettent donc dâ€™interprÃ©ter ce que reprÃ©sente chaque composante, en identifiant quelles variables y contribuent fortement (positivement ou nÃ©gativement).

Le cercle des corrÃ©lations permet dâ€™interprÃ©ter lâ€™influence des variables sur les composantes principales. Chaque variable est reprÃ©sentÃ©e par un vecteur dont la direction et la longueur indiquent sa contribution Ã  PC1 (axe X) et PC2 (axe Y). En gÃ©nÃ©ral, on se limite aux deux premiÃ¨res composantes principales (PC1 et PC2), car elles expliquent la majoritÃ© de la variance. Cette approche simplifie la visualisation et rend lâ€™interprÃ©tation plus claire, tandis que lâ€™ajout de composantes supplÃ©mentaires complique inutilement le graphique.

Quelques interprÃ©tations possibles :

- **ProximitÃ© dâ€™un axe** : Plus un vecteur est proche dâ€™un axe (PC1, PC2), plus la variable est liÃ©e Ã  cette composante.
- **Angle de 90Â°** : Si deux variables sont Ã  90Â°, elles sont non corrÃ©lÃ©es.
- **Angle aigu** : Un petit angle indique une forte corrÃ©lation positive : les deux variables Ã©voluent dans le mÃªme sens.
- **Angle proche de 180Â°** : Un angle proche de 180Â° signifie une corrÃ©lation nÃ©gative : lâ€™augmentation de lâ€™une entraÃ®ne la diminution de lâ€™autre.









# Derniergraphiqueici












## Mise en pratique
### <u>A. PrÃ©paration des donnÃ©es</u>
Afin dâ€™obtenir des rÃ©sultats fiables, il est dâ€™abord nÃ©cessaire de nettoyer les donnÃ©es : cela inclut la suppression ou le traitement des valeurs manquantes (NaN) ainsi que la gestion des valeurs aberrantes (outliers), qui peuvent fortement influencer lâ€™analyse.

Ensuite, il est important de ne conserver que les variables quantitatives, lâ€™ACP ne sâ€™appliquant pas aux donnÃ©es qualitatives.

Enfin, il faut standardiser les variables (centrer-rÃ©duire), afin quâ€™elles soient toutes sur la mÃªme Ã©chelle et que lâ€™ACP ne soit pas biaisÃ©e par des diffÃ©rences dâ€™unitÃ©s ou de grandeurs.

### <u>B. Application de l'ACP</u>

Nous commencons par dÃ©terminer le nombres de PC pour notre analyse.

![Image du Screeplot](screeplot.png)

Nous aurons donc 6 PC ! Voici le pourcentage de variance expliquÃ©e par chaque groupe en dÃ©tail :

![Image des %variance_expliquee](variance_expliquee.png)

Nous pouvons donc avoir notre matrice des **Loadings** avec nos coefficient directeur :

![Image des %variance_expliquee](loadings.png)
![Image du cercle des correlations](correlation_circle.png)


### <u>C. Analyse des rÃ©sultats</u>

## InterprÃ©tation

## Retours
- [ ] Pandoc pour exporter en PDF
- [ ] Obsidian ?
- [x] Installer l'extension Markdown All in One
